{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3823387-8aa7-4705-835d-8cec97e71159",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!pip install selenium pandas webdriver-manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb91e1a-d39b-4eb9-a163-852d83671a23",
   "metadata": {},
   "source": [
    "Scraping the Data From the SHL website using Selenium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e914a21-e9ed-4bad-97c0-5f7a5852463e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Error processing row: Message: no such element: Unable to locate element: {\"method\":\"tag name\",\"selector\":\"a\"}\n",
      "  (Session info: chrome=135.0.7049.96); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000104ffee10 cxxbridge1$str$ptr + 2817040\n",
      "1   chromedriver                        0x0000000104ff70ac cxxbridge1$str$ptr + 2784940\n",
      "2   chromedriver                        0x0000000104b3e8d8 cxxbridge1$string$len + 93028\n",
      "3   chromedriver                        0x0000000104b856a0 cxxbridge1$string$len + 383276\n",
      "4   chromedriver                        0x0000000104b7ad3c cxxbridge1$string$len + 339912\n",
      "5   chromedriver                        0x0000000104bc67b8 cxxbridge1$string$len + 649796\n",
      "6   chromedriver                        0x0000000104b79a80 cxxbridge1$string$len + 335116\n",
      "7   chromedriver                        0x0000000104fc3c98 cxxbridge1$str$ptr + 2575000\n",
      "8   chromedriver                        0x0000000104fc6f64 cxxbridge1$str$ptr + 2588004\n",
      "9   chromedriver                        0x0000000104fa3a20 cxxbridge1$str$ptr + 2443296\n",
      "10  chromedriver                        0x0000000104fc77e0 cxxbridge1$str$ptr + 2590176\n",
      "11  chromedriver                        0x0000000104f94b14 cxxbridge1$str$ptr + 2382100\n",
      "12  chromedriver                        0x0000000104fe79c4 cxxbridge1$str$ptr + 2721732\n",
      "13  chromedriver                        0x0000000104fe7b50 cxxbridge1$str$ptr + 2722128\n",
      "14  chromedriver                        0x0000000104ff6cf8 cxxbridge1$str$ptr + 2783992\n",
      "15  libsystem_pthread.dylib             0x0000000193d1ef94 _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x0000000193d19d34 thread_start + 8\n",
      "\n",
      "‚úÖ Found 24 valid assessment entries.\n",
      "‚úÖ Saved to shl_assessments.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Open catalog\n",
    "driver.get(\"https://www.shl.com/solutions/products/product-catalog/\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Grab all <tr> rows in the main catalog table\n",
    "rows = driver.find_elements(By.CSS_SELECTOR, \"table tr\")[1:]  # Skipping header\n",
    "\n",
    "catalog_links = []\n",
    "\n",
    "for row in rows:\n",
    "    try:\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "        link_elem = row.find_element(By.TAG_NAME, \"a\")\n",
    "        name = link_elem.text.strip()\n",
    "        url = link_elem.get_attribute(\"href\")\n",
    "\n",
    "        # Check green dot by class \".catalogue__circle.-yes\"\n",
    "        try:\n",
    "            cells[1].find_element(By.CSS_SELECTOR, \".catalogue__circle.-yes\")\n",
    "            remote_support = \"Yes\"\n",
    "        except:\n",
    "            remote_support = \"No\"\n",
    "\n",
    "        try:\n",
    "            cells[2].find_element(By.CSS_SELECTOR, \".catalogue__circle.-yes\")\n",
    "            adaptive_support = \"Yes\"\n",
    "        except:\n",
    "            adaptive_support = \"No\"\n",
    "\n",
    "        # Get test type\n",
    "        test_type = \", \".join([tt.text.strip() for tt in cells[3].find_elements(By.TAG_NAME, \"span\")])\n",
    "\n",
    "        catalog_links.append({\n",
    "            \"name\": name,\n",
    "            \"url\": url,\n",
    "            \"remote_support\": remote_support,\n",
    "            \"adaptive_support\": adaptive_support,\n",
    "            \"test_type\": test_type\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Error processing row:\", e)\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Found {len(catalog_links)} valid assessment entries.\")\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(catalog_links)\n",
    "df.to_csv(\"shl_assessments.csv\", index=False)\n",
    "print(\"‚úÖ Saved to shl_assessments.csv\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd049ef5-a29a-4584-bf46-6eebfaffe94b",
   "metadata": {},
   "source": [
    "Now we will Do Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31e91ef6-fb60-4317-a5f8-e7573d44af5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /opt/anaconda3/lib/python3.11/site-packages (0.8.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /opt/anaconda3/lib/python3.11/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /opt/anaconda3/lib/python3.11/site-packages (from google-generativeai) (2.24.1)\n",
      "Requirement already satisfied: google-api-python-client in /opt/anaconda3/lib/python3.11/site-packages (from google-generativeai) (2.162.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/anaconda3/lib/python3.11/site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.11/site-packages (from google-generativeai) (5.29.3)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.11/site-packages (from google-generativeai) (1.10.12)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.11/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/anaconda3/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/anaconda3/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/anaconda3/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/anaconda3/lib/python3.11/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import subprocess\n",
    "subprocess.run([\"pip\", \"install\", \"google-generativeai\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8bacba-3a20-46ff-a89a-043bb26f93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=\"your api key \")\n",
    "#api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db35aa50-75fc-4461-8d38-0853842a9344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    response = genai.embed_content(\n",
    "        model=\"models/embedding-001\",\n",
    "        content=text,\n",
    "        task_type=\"RETRIEVAL_DOCUMENT\"\n",
    "    )\n",
    "    return response['embedding']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ffb8f80-1c7e-4fa9-810c-04d05ce5561b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>remote_support</th>\n",
       "      <th>adaptive_support</th>\n",
       "      <th>test_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Account Manager Solution</td>\n",
       "      <td>https://www.shl.com/solutions/products/product...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>C, P, A, B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Administrative Professional - Short Form</td>\n",
       "      <td>https://www.shl.com/solutions/products/product...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A, K, P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agency Manager Solution</td>\n",
       "      <td>https://www.shl.com/solutions/products/product...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A, B, P, S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apprentice + 8.0 Job Focused Assessment</td>\n",
       "      <td>https://www.shl.com/solutions/products/product...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>B, P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apprentice 8.0 Job Focused Assessment</td>\n",
       "      <td>https://www.shl.com/solutions/products/product...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>B, P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name  \\\n",
       "0                  Account Manager Solution   \n",
       "1  Administrative Professional - Short Form   \n",
       "2                   Agency Manager Solution   \n",
       "3   Apprentice + 8.0 Job Focused Assessment   \n",
       "4     Apprentice 8.0 Job Focused Assessment   \n",
       "\n",
       "                                                 url remote_support  \\\n",
       "0  https://www.shl.com/solutions/products/product...            Yes   \n",
       "1  https://www.shl.com/solutions/products/product...            Yes   \n",
       "2  https://www.shl.com/solutions/products/product...            Yes   \n",
       "3  https://www.shl.com/solutions/products/product...            Yes   \n",
       "4  https://www.shl.com/solutions/products/product...            Yes   \n",
       "\n",
       "  adaptive_support   test_type  \n",
       "0              Yes  C, P, A, B  \n",
       "1              Yes     A, K, P  \n",
       "2              Yes  A, B, P, S  \n",
       "3               No        B, P  \n",
       "4               No        B, P  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"shl_assessments.csv\")  # or your actual CSV name\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a8ed24-35e7-4913-b388-ac4f1d6c503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"full_text\"] = (\n",
    "    df[\"name\"].fillna(\"\") +\n",
    "    \". Remote Support: \" + df[\"remote_support\"].fillna(\"\") +\n",
    "    \". Adaptive Support: \" + df[\"adaptive_support\"].fillna(\"\") +\n",
    "    \". Type: \" + df[\"test_type\"].fillna(\"\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d970b03-8939-4a31-b9f8-c332b480d3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:12<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"embedding\"] = df[\"full_text\"].progress_apply(get_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eee64b26-a4f1-4a6c-a7e5-b95c5ac2940a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings created and saved.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"shl_assessments_with_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8572068f-8273-4416-80ae-6858bded10d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       name  \\\n",
      "0                  Account Manager Solution   \n",
      "1  Administrative Professional - Short Form   \n",
      "2                   Agency Manager Solution   \n",
      "3   Apprentice + 8.0 Job Focused Assessment   \n",
      "4     Apprentice 8.0 Job Focused Assessment   \n",
      "\n",
      "                                                 url remote_support  \\\n",
      "0  https://www.shl.com/solutions/products/product...            Yes   \n",
      "1  https://www.shl.com/solutions/products/product...            Yes   \n",
      "2  https://www.shl.com/solutions/products/product...            Yes   \n",
      "3  https://www.shl.com/solutions/products/product...            Yes   \n",
      "4  https://www.shl.com/solutions/products/product...            Yes   \n",
      "\n",
      "  adaptive_support   test_type  \\\n",
      "0              Yes  C, P, A, B   \n",
      "1              Yes     A, K, P   \n",
      "2              Yes  A, B, P, S   \n",
      "3               No        B, P   \n",
      "4               No        B, P   \n",
      "\n",
      "                                           full_text  \\\n",
      "0  Account Manager Solution. Remote Support: Yes....   \n",
      "1  Administrative Professional - Short Form. Remo...   \n",
      "2  Agency Manager Solution. Remote Support: Yes. ...   \n",
      "3  Apprentice + 8.0 Job Focused Assessment. Remot...   \n",
      "4  Apprentice 8.0 Job Focused Assessment. Remote ...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [0.042632893, -0.029026862, -0.08385893, -0.03...  \n",
      "1  [0.035877075, -0.023441954, -0.057673637, -0.0...  \n",
      "2  [0.038987737, -0.02863536, -0.084629156, -0.01...  \n",
      "3  [0.03389121, -0.030675957, -0.08507269, -0.023...  \n",
      "4  [0.033945914, -0.03143384, -0.0843109, -0.0178...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your pickle file\n",
    "pickle_file_path = \"shl_assessments_with_embeddings.pkl\"\n",
    "\n",
    "# Load the pickle file into a DataFrame\n",
    "df = pd.read_pickle(pickle_file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4110a3-85a8-4f9a-852d-08f4e2addc95",
   "metadata": {},
   "source": [
    "We Start BUIlding Recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24872639-d412-40cb-884e-b37a38c37964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'assessment_name': 'Account Manager Solution', 'url': 'https://www.shl.com/solutions/products/product-catalog/view/account-manager-solution/', 'remote_testing': 'Yes', 'adaptive_support': 'Yes', 'duration': 'Not provided', 'test_type': 'C, P, A, B', 'similarity_score': 0.8335354235866881}\n",
      "{'assessment_name': 'Accounts Receivable (New)', 'url': 'https://www.shl.com/solutions/products/product-catalog/view/accounts-receivable-new/', 'remote_testing': 'Yes', 'adaptive_support': 'No', 'duration': 'Not provided', 'test_type': 'K', 'similarity_score': 0.8130644080931066}\n",
      "{'assessment_name': 'Agency Manager Solution', 'url': 'https://www.shl.com/solutions/products/product-catalog/view/agency-manager-solution/', 'remote_testing': 'Yes', 'adaptive_support': 'Yes', 'duration': 'Not provided', 'test_type': 'A, B, P, S', 'similarity_score': 0.8049733098488957}\n",
      "{'assessment_name': 'Branch Manager - Short Form', 'url': 'https://www.shl.com/solutions/products/product-catalog/view/branch-manager-short-form/', 'remote_testing': 'Yes', 'adaptive_support': 'No', 'duration': 'Not provided', 'test_type': 'A, B, P', 'similarity_score': 0.8009878887233282}\n",
      "{'assessment_name': 'Accounts Payable (New)', 'url': 'https://www.shl.com/solutions/products/product-catalog/view/accounts-payable-new/', 'remote_testing': 'Yes', 'adaptive_support': 'No', 'duration': 'Not provided', 'test_type': 'K', 'similarity_score': 0.8008204625817198}\n",
      "{'assessment_name': 'Cashier Solution', 'url': 'https://www.shl.com/solutions/products/product-catalog/view/cashier-solution/', 'remote_testing': 'Yes', 'adaptive_support': 'Yes', 'duration': 'Not provided', 'test_type': 'B, A, P', 'similarity_score': 0.7978273946429162}\n",
      "{'assessment_name': 'Administrative Professional - Short Form', 'url': 'https://www.shl.com/solutions/products/product-catalog/view/administrative-professional-short-form/', 'remote_testing': 'Yes', 'adaptive_support': 'Yes', 'duration': 'Not provided', 'test_type': 'A, K, P', 'similarity_score': 0.7943693820244755}\n",
      "{'assessment_name': 'Bank Operations Supervisor - Short Form', 'url': 'https://www.shl.com/solutions/products/product-catalog/view/bank-operations-supervisor-short-form/', 'remote_testing': 'Yes', 'adaptive_support': 'Yes', 'duration': 'Not provided', 'test_type': 'A, B, P, S', 'similarity_score': 0.7942288535577439}\n",
      "{'assessment_name': '.NET MVC (New)', 'url': 'https://www.shl.com/solutions/products/product-catalog/view/net-mvc-new/', 'remote_testing': 'Yes', 'adaptive_support': 'No', 'duration': 'Not provided', 'test_type': 'K', 'similarity_score': 0.7929918278512684}\n",
      "{'assessment_name': '.NET MVVM (New)', 'url': 'https://www.shl.com/solutions/products/product-catalog/view/net-mvvm-new/', 'remote_testing': 'Yes', 'adaptive_support': 'No', 'duration': 'Not provided', 'test_type': 'K', 'similarity_score': 0.7832382125324575}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the DataFrame from .pkl file\n",
    "with open(\"shl_assessments_with_embeddings.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# Convert the 'embedding' column into a matrix\n",
    "embeddings = np.vstack(df[\"embedding\"].values)  # shape: (n, 768)\n",
    "\n",
    "# Gemini embedding function (yours should already be working)\n",
    "def get_embedding(text: str):\n",
    "    response = genai.embed_content(\n",
    "        model=\"models/embedding-001\",\n",
    "        content=text,\n",
    "        task_type=\"RETRIEVAL_DOCUMENT\"\n",
    "    )\n",
    "    return response['embedding']\n",
    "\n",
    "# Final recommendation function\n",
    "def recommend_assessments(query: str, top_k: int = 10):\n",
    "    query_vector = np.array(get_embedding(query)).reshape(1, -1)\n",
    "    similarities = cosine_similarity(query_vector, embeddings)[0]\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        row = df.iloc[idx]\n",
    "        results.append({\n",
    "            \"assessment_name\": row[\"name\"],\n",
    "            \"url\": row[\"url\"],\n",
    "            \"remote_testing\": row[\"remote_support\"],      # corrected key\n",
    "            \"adaptive_support\": row[\"adaptive_support\"],\n",
    "            \"duration\": \"Not provided\",                    # optional: add if you later extract it\n",
    "            \"test_type\": row[\"test_type\"],\n",
    "            \"similarity_score\": float(similarities[idx])   # optional: useful for debugging\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Looking for a sales manager with good communication and leadership\"\n",
    "    recommendations = recommend_assessments(query)\n",
    "    for rec in recommendations:\n",
    "        print(rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11542cf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recommend_assessments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìä MAP@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:         \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_ap\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 86\u001b[0m     evaluate_model(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 63\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m     61\u001b[0m query \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     62\u001b[0m relevant \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelevant_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 63\u001b[0m results \u001b[38;5;241m=\u001b[39m recommend_assessments(query)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Debug: Print actual top 5 assessment names returned\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'recommend_assessments' is not defined"
     ]
    }
   ],
   "source": [
    "# Sample test queries with expected relevant keywords\n",
    "test_queries = [\n",
    "    {\n",
    "        \"query\": \"Looking to hire a data analyst with strong cognitive and logical skills\",\n",
    "        \"relevant_ids\": [\"Account\", \"Administrative\", \"Professional\", \"Receivable\", \"Payable\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Hiring for a customer service executive with good communication and empathy\",\n",
    "        \"relevant_ids\": [\"Administrative\", \"Account Manager\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Need a coding assessment for Java and Python\",\n",
    "        \"relevant_ids\": [\".NET\", \"Framework\", \"MVC\", \"Developer\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Searching for leadership potential test for team leads\",\n",
    "        \"relevant_ids\": [\"Manager\", \"Leadership\", \"Global Skills\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Need an adaptive and remote test for fresh graduates\",\n",
    "        \"relevant_ids\": [\"Apprentice\", \"Graduate\", \"Development\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Function to compute Recall@K\n",
    "def compute_recall_at_k(results, relevant, k):\n",
    "    retrieved = results[:k]\n",
    "    relevant_hits = sum(\n",
    "        any(rel.lower() in r['assessment_name'].lower() or rel.lower() in r['test_type'].lower()\n",
    "            for rel in relevant)\n",
    "        for r in retrieved\n",
    "    )\n",
    "    total_relevant = len(relevant)\n",
    "    return relevant_hits / total_relevant if total_relevant else 0\n",
    "\n",
    "# Function to compute MAP@K\n",
    "def compute_map_at_k(results, relevant, k):\n",
    "    hits = 0\n",
    "    sum_precisions = 0\n",
    "\n",
    "    for i in range(min(k, len(results))):\n",
    "        r = results[i]\n",
    "        is_relevant = any(\n",
    "            rel.lower() in r['assessment_name'].lower() or rel.lower() in r['test_type'].lower()\n",
    "            for rel in relevant\n",
    "        )\n",
    "        if is_relevant:\n",
    "            hits += 1\n",
    "            sum_precisions += hits / (i + 1)\n",
    "\n",
    "    return sum_precisions / min(len(relevant), k) if relevant else 0\n",
    "\n",
    "# Master evaluation function\n",
    "def evaluate_model(k=5):\n",
    "    total_recall = 0\n",
    "    total_map = 0\n",
    "    N = len(test_queries)\n",
    "\n",
    "    for i, test in enumerate(test_queries, 1):\n",
    "        query = test[\"query\"]\n",
    "        relevant = test[\"relevant_ids\"]\n",
    "        results = recommend_assessments(query)\n",
    "\n",
    "        # Debug: Print actual top 5 assessment names returned\n",
    "        print(f\"\\n[{i}] Query: {query}\")\n",
    "        for res in results[:k]:\n",
    "            print(\"   ‚Üí\", res['assessment_name'])\n",
    "\n",
    "        recall = compute_recall_at_k(results, relevant, k)\n",
    "        ap = compute_map_at_k(results, relevant, k)\n",
    "\n",
    "        print(f\"‚Üí Recall@{k}: {recall:.2f}\")\n",
    "        print(f\"‚Üí AP@{k}:     {ap:.2f}\")\n",
    "\n",
    "        total_recall += recall\n",
    "        total_map += ap\n",
    "\n",
    "    mean_recall = total_recall / N\n",
    "    mean_ap = total_map / N\n",
    "\n",
    "    print(f\"\\nüìä Mean Recall@{k}: {mean_recall:.2f}\")\n",
    "    print(f\"üìä MAP@{k}:         {mean_ap:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_model(k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
